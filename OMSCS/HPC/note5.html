<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>High Performance Computing 5 | Work Span Model &mdash; serenefield-sphinx  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="note6.html" />
    <link rel="prev" title="High Performance Computing 4ï½œCache Oblivious Algorithms" href="note4.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            serenefield-sphinx
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">DevOps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html">ğŸ¦« golang</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#docker">â›´ï¸  Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#ckad">â˜¸ï¸  CKAD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#advanced-k8s">â›µï¸  Advanced K8s</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#apache-solr">ğŸ¥  Apache Solr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#hadoop-ecosystem">ğŸ˜  Hadoop Ecosystem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#web-application">ğŸ“„  Web Application</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Japanese</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html">ğŸ¯  Learning Resource</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html#n5">ğŸ¯  N5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html#n4">ğŸ¯  N4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html#id1">ğŸ–¥ï¸ã€€é…ä¿¡</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html#id2">ğŸ¶  éŸ³æ¥½</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guitar</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Guitar/index.html">ğŸ¸  Level 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Guitar/index.html#level-2">ğŸ¸  Level 2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">OMSCS</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">ğŸ’»  Computer Network</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html#high-performance-computing">ğŸ’»  High Performance Computing</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="note1.html">High Performance Computing 1 | Memory Locality Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="note2.html">High Performance Computing 2 | Algorithmic Time: Energy and Power</a></li>
<li class="toctree-l2"><a class="reference internal" href="note3.html">High Performance Computing 3 | I/O Avoiding Algorithms</a></li>
<li class="toctree-l2"><a class="reference internal" href="note4.html">High Performance Computing 4ï½œCache Oblivious Algorithms</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">High Performance Computing 5 | Work Span Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#basic-concepts">1. Basic Concepts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#dynamic-multithreading-models">(1) Dynamic Multithreading Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multithreading-dags">(2) Multithreading DAGs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scheduling">(3) Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dag-example-sequential-reduction">(4) DAG Example: Sequential Reduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dag-example-2-btree-reduction">(5) DAG Example 2: Btree Reduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="#work-and-span">(6) Work and Span</a></li>
<li class="toctree-l4"><a class="reference internal" href="#processors-and-w-s">(7) Processors and W/S</a></li>
<li class="toctree-l4"><a class="reference internal" href="#average-available-parallelism">(8) Average Available Parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-span-law">(9) The Span Law</a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-work-law">(10) The Work Law</a></li>
<li class="toctree-l4"><a class="reference internal" href="#work-span-law">(11) Work-Span Law</a></li>
<li class="toctree-l4"><a class="reference internal" href="#phases">(12) Phases</a></li>
<li class="toctree-l4"><a class="reference internal" href="#brent-s-theorem-on-the-upper-bound">(12) Brentâ€™s Theorem on the Upper Bound</a></li>
<li class="toctree-l4"><a class="reference internal" href="#meanings-of-the-brent-s-theorem">(13) Meanings of the Brentâ€™s Theorem</a></li>
<li class="toctree-l4"><a class="reference internal" href="#speedup">(14) Speedup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#work-optimality">(15) Work Optimality</a></li>
<li class="toctree-l4"><a class="reference internal" href="#weak-scalability">(16) Weak Scalability</a></li>
<li class="toctree-l4"><a class="reference internal" href="#concurrency-primitive-1-spawn-and-sync">(17) Concurrency Primitive 1: Spawn and Sync</a></li>
<li class="toctree-l4"><a class="reference internal" href="#application-of-spawn-and-sync-framework">(18) Application of Spawn and Sync Framework</a></li>
<li class="toctree-l4"><a class="reference internal" href="#work-optimality-low-span">(19) Work-Optimality Low-Span</a></li>
<li class="toctree-l4"><a class="reference internal" href="#concurrency-primitive-2-parfor">(20) Concurrency Primitive 2: parfor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#data-race">(21) Data Race</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="note7.html">High Performance Computing 7 | Scan and Rank List</a></li>
<li class="toctree-l2"><a class="reference internal" href="note8.html">High Performance Computing 8 | Parallel on Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="note9.html">High Performance Computing 9 | Midterm Review</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#information-security">ğŸ’»  Information Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Arts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Arts/index.html">ğŸ–¼ï¸  Drawing - Perspective</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Arts/index.html#blender-basic">ğŸ§Š  Blender - Basic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Arts/index.html#blender-anime">ğŸ¥  Blender - Anime</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tests</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tests/index.html">ğŸ§ª  Sphinx Tests</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">serenefield-sphinx</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">ğŸ’»  Computer Network</a></li>
      <li class="breadcrumb-item active">High Performance Computing 5 | Work Span Model</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/OMSCS/HPC/note5.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="high-performance-computing-5-work-span-model">
<h1>High Performance Computing 5 | Work Span Model<a class="headerlink" href="#high-performance-computing-5-work-span-model" title="Permalink to this heading">ïƒ</a></h1>
<section id="basic-concepts">
<h2>1. Basic Concepts<a class="headerlink" href="#basic-concepts" title="Permalink to this heading">ïƒ</a></h2>
<section id="dynamic-multithreading-models">
<h3>(1) Dynamic Multithreading Models<a class="headerlink" href="#dynamic-multithreading-models" title="Permalink to this heading">ïƒ</a></h3>
<p>The dynamic multithreading models are consisted of two parts,</p>
<ul class="simple">
<li><p>computation can be represented by a DAG</p></li>
<li><p>pseudocode notation which will be defined when we execute one of these algorithms, it generates a computational DAG</p></li>
</ul>
<p>In this lesson we will focusing on how to create the DAGs instead of how to map these DAGs to cores or execute them.</p>
</section>
<section id="multithreading-dags">
<h3>(2) Multithreading DAGs<a class="headerlink" href="#multithreading-dags" title="Permalink to this heading">ïƒ</a></h3>
<p>In a DAG, each node is an operation and the edges are dependencies. We should also assume that there will be only one starting vertex and one exit vertex, or we should add one starting vertex or/and one exit vertex to make things simple in some cases.</p>
<p>When an operation is ready to go (means it has no dependencies), then we can execute it on any of the available cores.</p>
</section>
<section id="scheduling">
<h3>(3) Scheduling<a class="headerlink" href="#scheduling" title="Permalink to this heading">ïƒ</a></h3>
<p>At every step of the computation, the problem of how to take free units of work and assign them to processors is called a scheduling problem.</p>
</section>
<section id="dag-example-sequential-reduction">
<h3>(4) DAG Example: Sequential Reduction<a class="headerlink" href="#dag-example-sequential-reduction" title="Permalink to this heading">ïƒ</a></h3>
<p>Letâ€™s suppose we have the following pseudocode,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">let</span> <span class="n">A</span> <span class="o">=</span> <span class="n">array</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="n">to</span> <span class="n">n</span> <span class="n">do</span><span class="p">:</span>
    <span class="n">s</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</pre></div>
</div>
<p>So in the DAG, there should be two nodes in each iteration,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Load</span> <span class="pre">A[i]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Add</span></code></p></li>
</ul>
<p>There will also be an edge between them because the Add can not start if we did not load the <code class="docutils literal notranslate"><span class="pre">A[i]</span></code>. However, the loads of <code class="docutils literal notranslate"><span class="pre">A[i]</span></code>s have no dependencies but the add operation in each iteration relies on the load of <code class="docutils literal notranslate"><span class="pre">A[i]</span></code> and the add operation in the last iteration.</p>
<p>However, there should be dependence goes from the last add operation to the current load operation. This is because the loop is being executed in sequential and we have what is called the control dependency. But for now letâ€™s ignore these dependencies.</p>
<p>Thus, the time PRAM takes to execute this DAG with <code class="docutils literal notranslate"><span class="pre">p</span></code> processors should be,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">n</span><span class="o">/</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">n</span>
</pre></div>
</div>
<p>So the time should be,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">n</span>
</pre></div>
</div>
<p>This result matches our intuition.</p>
</section>
<section id="dag-example-2-btree-reduction">
<h3>(5) DAG Example 2: Btree Reduction<a class="headerlink" href="#dag-example-2-btree-reduction" title="Permalink to this heading">ïƒ</a></h3>
<p>For a binary tree reduction, the time PRAM takes to execute this DAG with <code class="docutils literal notranslate"><span class="pre">p</span></code> processors assuming <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&gt;=</span> <span class="pre">n</span></code> in one level would be,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">l</span><span class="p">)</span> <span class="o">=</span> <span class="n">O</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>And because there are <code class="docutils literal notranslate"><span class="pre">logn</span></code> levels, then,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">=</span> <span class="n">O</span><span class="p">(</span><span class="n">logn</span><span class="p">)</span>
</pre></div>
</div>
<p>Here because the tree layout generates more parallism, we may choose it as a better algorithm.</p>
</section>
<section id="work-and-span">
<h3>(6) Work and Span<a class="headerlink" href="#work-and-span" title="Permalink to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p>Work (note as <code class="docutils literal notranslate"><span class="pre">W(n)</span></code>): how many vertices does it have in total</p></li>
<li><p>Span (note as <code class="docutils literal notranslate"><span class="pre">D(n)</span></code>): how many vertices on the longest path</p></li>
</ul>
<p>The longest path is also called the cirtical path.</p>
</section>
<section id="processors-and-w-s">
<h3>(7) Processors and W/S<a class="headerlink" href="#processors-and-w-s" title="Permalink to this heading">ïƒ</a></h3>
<p>Now suppose we have only one processor <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">=</span> <span class="pre">1</span></code>, then the total time we spend is only based on how many work we have. So,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T_1</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">=</span> <span class="n">W</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
<p>However, when we have infinite processors <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">=</span> <span class="pre">âˆ</span></code>, the time is actually depending on the longest path we have in the DAG so,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">T_inf</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">=</span> <span class="n">D</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="average-available-parallelism">
<h3>(8) Average Available Parallelism<a class="headerlink" href="#average-available-parallelism" title="Permalink to this heading">ïƒ</a></h3>
<p>The ratio of <code class="docutils literal notranslate"><span class="pre">W</span></code> by <code class="docutils literal notranslate"><span class="pre">D</span></code> measures the amount of work per critical path vertex. So,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Avg</span><span class="o">.</span> <span class="n">Para</span> <span class="o">=</span> <span class="n">W</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">D</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
<p>This is useful because <code class="docutils literal notranslate"><span class="pre">W/D</span></code> shows the number of processors we need in a PRAM model and it shows the average busy processors we have for a DAG.</p>
</section>
<section id="the-span-law">
<h3>(9) The Span Law<a class="headerlink" href="#the-span-law" title="Permalink to this heading">ïƒ</a></h3>
<p>Because the span is the workload when the program is fully parallel, then we can know the span should be the lower bound of the time to execute,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">D</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="the-work-law">
<h3>(10) The Work Law<a class="headerlink" href="#the-work-law" title="Permalink to this heading">ïƒ</a></h3>
<p>When thereâ€™s no critical path, the lower bound of the time should be evenly seperate the work onto <code class="docutils literal notranslate"><span class="pre">p</span></code> processors so that,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">W</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
<p>This is called the work law.</p>
</section>
<section id="work-span-law">
<h3>(11) Work-Span Law<a class="headerlink" href="#work-span-law" title="Permalink to this heading">ïƒ</a></h3>
<p>Because both of the laws above holds, we can have the following work-span law,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nb">max</span><span class="p">{</span><span class="n">D</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">ceil</span><span class="p">(</span><span class="n">W</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">/</span><span class="n">p</span><span class="p">)}</span>
</pre></div>
</div>
</section>
<section id="phases">
<h3>(12) Phases<a class="headerlink" href="#phases" title="Permalink to this heading">ïƒ</a></h3>
<p>Before we continue, letâ€™s see some rules to divide a DAG to some phases.</p>
<ul class="simple">
<li><p>Each phase should have 1 critical path vertex</p></li>
<li><p>Non critical path vertices in each phase are independent</p></li>
<li><p>Every vertex must appear in some phase</p></li>
</ul>
<p>Under this definition, we have the time for execution on phase <code class="docutils literal notranslate"><span class="pre">k</span></code> should be,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">t_k</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">W_k</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
<p>And because the time in each phase sums up to the total time we need, then,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">{</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="o">~</span><span class="n">D</span><span class="p">}(</span><span class="n">t_k</span><span class="p">)</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">{</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="o">~</span><span class="n">D</span><span class="p">}(</span><span class="n">ceil</span><span class="p">(</span><span class="n">W_k</span> <span class="o">/</span> <span class="n">p</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="brent-s-theorem-on-the-upper-bound">
<h3>(12) Brentâ€™s Theorem on the Upper Bound<a class="headerlink" href="#brent-s-theorem-on-the-upper-bound" title="Permalink to this heading">ïƒ</a></h3>
<p>Now assume we know the fact that,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ceil</span><span class="p">(</span><span class="n">a</span><span class="o">/</span><span class="n">b</span><span class="p">)</span> <span class="o">=</span> <span class="n">floor</span><span class="p">((</span><span class="n">a</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="n">b</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
</pre></div>
</div>
<p>Then the equation above can be written to,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">{</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="o">~</span><span class="n">D</span><span class="p">}(</span><span class="n">t_k</span><span class="p">)</span> <span class="o">=</span> <span class="n">SUM</span><span class="p">{</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="o">~</span><span class="n">D</span><span class="p">}(</span><span class="n">floor</span><span class="p">((</span><span class="n">W_k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Because,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">floor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">x</span>
</pre></div>
</div>
<p>Then we have,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span> <span class="o">&lt;=</span> <span class="n">SUM</span><span class="p">{</span><span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="o">~</span><span class="n">D</span><span class="p">}((</span><span class="n">W_k</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>As a result we have,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Tp</span> <span class="o">&lt;=</span> <span class="p">(</span><span class="n">W</span> <span class="o">-</span> <span class="n">D</span><span class="p">)</span> <span class="o">/</span> <span class="n">P</span> <span class="o">+</span> <span class="n">D</span>
</pre></div>
</div>
<p>And this is the upper bound we would love to see.</p>
</section>
<section id="meanings-of-the-brent-s-theorem">
<h3>(13) Meanings of the Brentâ€™s Theorem<a class="headerlink" href="#meanings-of-the-brent-s-theorem" title="Permalink to this heading">ïƒ</a></h3>
<p>From Brentâ€™s theorem, we can find out that the time to execute a DAG is no more than the time to execute the critical path plus to execute the everything off the critical path using <code class="docutils literal notranslate"><span class="pre">p</span></code> processors.</p>
<p>Note that the Brentâ€™s theorem is a upper bound and it is usually slack in the real cases.</p>
</section>
<section id="speedup">
<h3>(14) Speedup<a class="headerlink" href="#speedup" title="Permalink to this heading">ïƒ</a></h3>
<p>The speedup measures how good a DAG is and it is defined as the ratio of the best sequential time over the parallel time. â€œbestâ€ means we donâ€™t choose a terrible sequence as our benchmark.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Speedup</span> <span class="o">=</span> <span class="n">best</span> <span class="n">sequential</span> <span class="n">time</span> <span class="o">/</span> <span class="n">parallel</span> <span class="n">time</span>
        <span class="o">=</span> <span class="n">T</span><span class="s1">&#39;(n) / Tp(n)</span>
        <span class="o">=</span> <span class="n">W</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">Tp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
<p>Idealy, we want the time to be <code class="docutils literal notranslate"><span class="pre">p</span></code> times faster then the best sequential algorithm called the ideal speedup,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">=</span> <span class="n">Î˜</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
<p>Now, letâ€™s pug in the Brentâ€™s theorem and then the lower bound of speedup we have here is,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">W</span><span class="s1">&#39; / ((W - D) / P + D)</span>
</pre></div>
</div>
<p>This is also,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sp</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">P</span> <span class="o">/</span> <span class="p">(</span><span class="n">W</span><span class="o">/</span><span class="n">W</span><span class="s1">&#39; + (p-1)/(W&#39;</span><span class="o">/</span><span class="n">D</span><span class="p">))</span>
</pre></div>
</div>
<p>This means that if we want to achieve to the speedup goal of <code class="docutils literal notranslate"><span class="pre">P</span></code>, we have to pay a penality which is <code class="docutils literal notranslate"><span class="pre">W/W'</span> <span class="pre">+</span> <span class="pre">(p-1)/(W'/D)</span></code>. And in the best case, we want the denominator to be constant,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span><span class="o">/</span><span class="n">W</span><span class="s1">&#39; + (P-1)/(W&#39;</span><span class="o">/</span><span class="n">D</span><span class="p">)</span> <span class="o">=</span> <span class="n">O</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="work-optimality">
<h3>(15) Work Optimality<a class="headerlink" href="#work-optimality" title="Permalink to this heading">ïƒ</a></h3>
<p>To achieve,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span><span class="o">/</span><span class="n">W</span><span class="s1">&#39; + (P-1)/(W&#39;</span><span class="o">/</span><span class="n">D</span><span class="p">)</span> <span class="o">=</span> <span class="n">O</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>The first thing is to make,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span><span class="o">/</span><span class="n">W</span><span class="s1">&#39; = O(1)</span>
</pre></div>
</div>
<p>So the work of the parallel slgorithm has to match to the best sequential algorithm so,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="s1">&#39;</span>
</pre></div>
</div>
</section>
<section id="weak-scalability">
<h3>(16) Weak Scalability<a class="headerlink" href="#weak-scalability" title="Permalink to this heading">ïƒ</a></h3>
<p>Second we need to have,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">P</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">W</span><span class="s1">&#39;/D) = O(1)</span>
</pre></div>
</div>
<p>So,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">P</span> <span class="o">=</span> <span class="n">O</span><span class="p">(</span><span class="n">W</span><span class="s1">&#39;/D)</span>
</pre></div>
</div>
<p>This is also,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span><span class="s1">&#39;/P = Î©(D)</span>
</pre></div>
</div>
<p>This means the work per processor has to grow proportional to the span. And because the span depends on the problem size <code class="docutils literal notranslate"><span class="pre">n</span></code>, so work per processor should grow as some function of <code class="docutils literal notranslate"><span class="pre">n</span></code>. This is called weak scalability.</p>
</section>
<section id="concurrency-primitive-1-spawn-and-sync">
<h3>(17) Concurrency Primitive 1: Spawn and Sync<a class="headerlink" href="#concurrency-primitive-1-spawn-and-sync" title="Permalink to this heading">ïƒ</a></h3>
<ul class="simple">
<li><p>Spawn: the target of a spawn keyword is either a function call or a procedure call and it is a signal to the runtime or compiler that the target is an independent unit of work</p></li>
<li><p>Sync: the sync keywork means thatâ€™s a dependence of the the current operation</p></li>
</ul>
<p>Here are some notes,</p>
<ul class="simple">
<li><p>Sync matches any spawn in the same frame</p></li>
<li><p>Thereâ€™s always an implicit sync before returning to the caller</p></li>
</ul>
</section>
<section id="application-of-spawn-and-sync-framework">
<h3>(18) Application of Spawn and Sync Framework<a class="headerlink" href="#application-of-spawn-and-sync-framework" title="Permalink to this heading">ïƒ</a></h3>
<p>The good thing of spawn-sync is that we can almost do exactly the same thing for a sequential model or a work-span model.</p>
<ul class="simple">
<li><p>for the work, we just count spawns and syncs as 1 so that it will be the sames as analyzing a sequential work</p></li>
<li><p>for the span, the span in a frame depends only on the spawn that has the longest path.</p></li>
</ul>
</section>
<section id="work-optimality-low-span">
<h3>(19) Work-Optimality Low-Span<a class="headerlink" href="#work-optimality-low-span" title="Permalink to this heading">ïƒ</a></h3>
<p>As a parallel algorithm designer, one of the goals is to achieve â€œWork-Optimality Low-Spanâ€, this means that we have,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">W</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">=</span> <span class="n">W</span><span class="s1">&#39;(n)</span>
</pre></div>
</div>
<p>As well as a polylogarithmic span</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">D</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">=</span> <span class="n">O</span><span class="p">(</span><span class="n">log</span><span class="o">^</span><span class="n">k</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
</pre></div>
</div>
<p>This is motivated because <code class="docutils literal notranslate"><span class="pre">W/D</span> <span class="pre">=</span> <span class="pre">O(n/log^k(n))</span></code> which grows with n and close to linearly</p>
</section>
<section id="concurrency-primitive-2-parfor">
<h3>(20) Concurrency Primitive 2: parfor<a class="headerlink" href="#concurrency-primitive-2-parfor" title="Permalink to this heading">ïƒ</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">parfor</span></code> before a loop means a for loop with iterations that can be executed without dependencies. A <code class="docutils literal notranslate"><span class="pre">parfor</span></code> will create a implicit sync that will join after the loop.</p>
<ul class="simple">
<li><p>Work: O(n)</p></li>
<li><p>Span: O(1) in theory</p></li>
</ul>
<p>In fact the <code class="docutils literal notranslate"><span class="pre">parfor</span></code> is either implemented linearly or logarithmic and we should assume <code class="docutils literal notranslate"><span class="pre">parfor</span></code> uses logarithmic implementation from now on.</p>
</section>
<section id="data-race">
<h3>(21) Data Race<a class="headerlink" href="#data-race" title="Permalink to this heading">ïƒ</a></h3>
<p>Data race means at least one read and at least one write may happen at the same memory location at the same time.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="note4.html" class="btn btn-neutral float-left" title="High Performance Computing 4ï½œCache Oblivious Algorithms" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="note6.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Yufeng Xing.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>