<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Computer Network 9ÔΩúPacket Classification, Packet Scheduling, Traffic Scheduling &mdash; serenefield-sphinx  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/style.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="High Performance Computing 1 | Memory Locality Theory" href="../HPC/note1.html" />
    <link rel="prev" title="Computer Network 8 | Introduction to Routers and Prefix Match" href="note8.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            serenefield-sphinx
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">DevOps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html">‚õ¥Ô∏è  Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#ckad">‚ò∏Ô∏è  CKAD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#advanced-k8s">‚õµÔ∏è  Advanced K8s</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#apache-solr">ü•ê  Apache Solr</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../devops/index.html#hadoop-ecosystem">üêò  Hadoop Ecosystem</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Japanese</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html">üèØ  N5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html#n4">üèØ  N4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Jap/index.html#id1">üé∂  Èü≥Ê•Ω</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guitar</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Guitar/index.html">üé∏  Level 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Guitar/index.html#level-2">üé∏  Level 2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">OMSCS</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">üíª  Computer Network</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="note1.html">Computer Network 1ÔΩúIntroduction to Computer Network, OSI Model, Principles, and Devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="note2.html">Computer Network 2 | Introduction to Transport Layer, UDP and TCP, Congestion Control, Fairness</a></li>
<li class="toctree-l2"><a class="reference internal" href="note3.html">Computer Network 3 | Spanning Tree Protocol Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="note4.html">Computer Network 4 | Introduction to Routing, Link State, Distance Vector, RIP, OSPF, Hot Potato Routing</a></li>
<li class="toctree-l2"><a class="reference internal" href="note5.html">Computer Network 5 | Distance Vector Implementation</a></li>
<li class="toctree-l2"><a class="reference internal" href="note6.html">Computer Network 6 | Introduction to Autonomous Systems, BGP Routing, and Peering Through IXPs</a></li>
<li class="toctree-l2"><a class="reference internal" href="note7.html">Computer Network 7ÔΩúImplement MiniNet</a></li>
<li class="toctree-l2"><a class="reference internal" href="note8.html">Computer Network 8 | Introduction to Routers and Prefix Match</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Computer Network 9ÔΩúPacket Classification, Packet Scheduling, Traffic Scheduling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#packet-classification">1. Packet Classification</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#reasons-for-packet-classification">(1) Reasons for Packet Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="#variants-of-packet-classification">(2) Variants of Packet Classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packet-classification-simple-solution-1-linear-search">(3) Packet Classification Simple Solution 1: Linear Search</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packet-classification-simple-solution-2-caching">(4) Packet Classification Simple Solution 2: Caching</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packet-classification-simple-solution-3-passing-labels">(5) Packet Classification Simple Solution 3: Passing Labels</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packet-classification-fast-solution-1-set-pruning-tries">(6) Packet Classification Fast Solution 1: Set-Pruning Tries</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packet-classification-fast-solution-2-backtracking">(6) Packet Classification Fast Solution 2: Backtracking</a></li>
<li class="toctree-l4"><a class="reference internal" href="#packet-classification-fast-solution-3-grid-of-tries">(7) Packet Classification Fast Solution 3: Grid of Tries</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#packet-scheduling">2. Packet Scheduling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#reasons-for-scheduling">(1) Reasons for Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scheduling-algorithm-1-take-a-ticket-algorithm">(2) Scheduling Algorithm 1: Take a Ticket Algorithm</a></li>
<li class="toctree-l4"><a class="reference internal" href="#problem-of-take-a-ticket-head-of-line-hol-blocking">(3) Problem of Take a Ticket: Head of Line (HOL) Blocking</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hol-avoidance-solution-1-faster-fabric">(4) HOL Avoidance Solution 1: Faster Fabric</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hol-avoidance-solution-2-parallel-iterative-matching">(5) HOL Avoidance Solution 2: Parallel Iterative Matching</a></li>
<li class="toctree-l4"><a class="reference internal" href="#scheduling-algorithm-2-fifo-with-tail-drop">(6) Scheduling Algorithm 2: FIFO with Tail Drop</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quality-of-service-qos">(7) Quality of Service (QoS)</a></li>
<li class="toctree-l4"><a class="reference internal" href="#reasons-for-complex-scheduling-algorithms">(8) Reasons for Complex Scheduling Algorithms</a></li>
<li class="toctree-l4"><a class="reference internal" href="#fifo-with-tail-drop-vs-round-robin">(9) FIFO with Tail Drop vs Round Robin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#complex-scheduling-algorithm-1-1-bit-by-bit-round-robin">(9) Complex Scheduling Algorithm 1-1: Bit-by-bit Round Robin</a></li>
<li class="toctree-l4"><a class="reference internal" href="#complex-scheduling-algorithm-1-2-packet-level-fair-queuing">(10) Complex Scheduling Algorithm 1-2: Packet-level Fair Queuing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#complex-scheduling-algorithm-2-deficit-round-robin-drr">(11) Complex Scheduling Algorithm 2: Deficit Round Robin (DRR)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#traffic-scheduling">3. Traffic Scheduling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#reasons-for-traffic-scheduling">(1) Reasons for Traffic Scheduling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#traffic-policing">(2) Traffic Policing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#traffic-shaping">(3) Traffic Shaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="#traffic-scheduling-approach-1-token-bucket-shaping">(4) Traffic Scheduling Approach 1: Token Bucket Shaping</a></li>
<li class="toctree-l4"><a class="reference internal" href="#traffic-scheduling-approach-1-token-bucket-policing">(5) Traffic Scheduling Approach 1: Token Bucket Policing</a></li>
<li class="toctree-l4"><a class="reference internal" href="#traffic-scheduling-approach-2-leaky-bucket">(6) Traffic Scheduling Approach 2: Leaky Bucket</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#high-performance-computing">üíª  High Performance Computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#information-security">üíª  Information Security</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Arts</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../Arts/index.html">üñºÔ∏è  Drawing - Perspective</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Arts/index.html#blender-basic">üßä  Blender - Basic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Arts/index.html#blender-anime">üé•  Blender - Anime</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tests</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tests/index.html">üß™  Sphinx Tests</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">serenefield-sphinx</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">üíª  Computer Network</a></li>
      <li class="breadcrumb-item active">Computer Network 9ÔΩúPacket Classification, Packet Scheduling, Traffic Scheduling</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/OMSCS/CN/note9.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="computer-network-9-packet-classification-packet-scheduling-traffic-scheduling">
<h1>Computer Network 9ÔΩúPacket Classification, Packet Scheduling, Traffic Scheduling<a class="headerlink" href="#computer-network-9-packet-classification-packet-scheduling-traffic-scheduling" title="Permalink to this heading">ÔÉÅ</a></h1>
<section id="packet-classification">
<h2>1. Packet Classification<a class="headerlink" href="#packet-classification" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="reasons-for-packet-classification">
<h3>(1) Reasons for Packet Classification<a class="headerlink" href="#reasons-for-packet-classification" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Network requires quality of service and secutiry guarantees when the internet becomes more complex. Therefore, forwarding based on prefix match is not enough and we need to handle packets based on multiple criteria,</p>
<ul class="simple">
<li><p>TCP flags</p></li>
<li><p>source addresses</p></li>
<li><p>etc.</p></li>
</ul>
</section>
<section id="variants-of-packet-classification">
<h3>(2) Variants of Packet Classification<a class="headerlink" href="#variants-of-packet-classification" title="Permalink to this heading">ÔÉÅ</a></h3>
<ul class="simple">
<li><p>Firewall: implement on routers to filter out unwanted traffic</p></li>
<li><p>Resource Reservation Protocols: For example, <code class="docutils literal notranslate"><span class="pre">DiffServ</span></code> has been used to reserve bandwidth</p></li>
<li><p>Routing Based on Traffic Type: helps avoid delay for time-sensitive services (e.g. videos)</p></li>
</ul>
</section>
<section id="packet-classification-simple-solution-1-linear-search">
<h3>(3) Packet Classification Simple Solution 1: Linear Search<a class="headerlink" href="#packet-classification-simple-solution-1-linear-search" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The first simple approach to implement packet classification is <strong>linear search</strong>. This solution can be reasonable for a few rules but the time to search through a large database that may have thousands of rules can be prohibitive.</p>
<p><strong>Firewall</strong> implementations perform a linear search of the rules database and keep track of the best-match rule.</p>
</section>
<section id="packet-classification-simple-solution-2-caching">
<h3>(4) Packet Classification Simple Solution 2: Caching<a class="headerlink" href="#packet-classification-simple-solution-2-caching" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Another apporach is to cache the results so that future searches can run faster. However, this approach has two problems,</p>
<ul class="simple">
<li><p>We still need a search for the cache misses</p></li>
<li><p>We need to search in cache‚Äôs space. This is much faster than a linear search but it can still result in poor performance</p></li>
</ul>
</section>
<section id="packet-classification-simple-solution-3-passing-labels">
<h3>(5) Packet Classification Simple Solution 3: Passing Labels<a class="headerlink" href="#packet-classification-simple-solution-3-passing-labels" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The idea of passing labels is that when A sends a packet to B, the packet will be labelled somewhere so that intermediate routers don‚Äôt have to conduct the packet classification.</p>
<p>This approach is widely used in some protocols,</p>
<ul class="simple">
<li><p>Multiprotocol Label Switching (MPLS): one router stores the label in a MPLS header so no need for future classification</p></li>
<li><p>DiffServ: mark packets edges for special quality of service</p></li>
</ul>
</section>
<section id="packet-classification-fast-solution-1-set-pruning-tries">
<h3>(6) Packet Classification Fast Solution 1: Set-Pruning Tries<a class="headerlink" href="#packet-classification-fast-solution-1-set-pruning-tries" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Using pruning tries for the rules provide a faster solution for packet classification. Let‚Äôs see an example. Suppose we have the following rules to classify,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">R1</span><span class="p">:</span>    <span class="n">Dest</span> <span class="o">=</span> <span class="mi">0</span><span class="o">*</span>    <span class="n">Source</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span>
<span class="n">R2</span><span class="p">:</span>    <span class="n">Dest</span> <span class="o">=</span> <span class="mi">0</span><span class="o">*</span>    <span class="n">Source</span> <span class="o">=</span> <span class="mi">01</span><span class="o">*</span>
<span class="n">R3</span><span class="p">:</span>    <span class="n">Dest</span> <span class="o">=</span> <span class="mi">0</span><span class="o">*</span>    <span class="n">Source</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span>
<span class="n">R4</span><span class="p">:</span>    <span class="n">Dest</span> <span class="o">=</span> <span class="mi">00</span><span class="o">*</span>   <span class="n">Source</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span>
<span class="n">R5</span><span class="p">:</span>    <span class="n">Dest</span> <span class="o">=</span> <span class="mi">00</span><span class="o">*</span>   <span class="n">Source</span> <span class="o">=</span> <span class="mi">11</span><span class="o">*</span>
<span class="n">R6</span><span class="p">:</span>    <span class="n">Dest</span> <span class="o">=</span> <span class="mi">10</span><span class="o">*</span>   <span class="n">Source</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span>
<span class="n">R7</span><span class="p">:</span>    <span class="n">Dest</span> <span class="o">=</span> <span class="o">*</span>     <span class="n">Source</span> <span class="o">=</span> <span class="mi">00</span><span class="o">*</span>
</pre></div>
</div>
<p>Then we can build a prune trie based on the destinations,</p>
<p><img alt="" src="https://i.imgur.com/9cJr9q7.png" /></p>
<p>However, this is only half of the result and we also have to store the source filters somewhere. For example, suppose a packet comes with <code class="docutils literal notranslate"><span class="pre">Dest</span> <span class="pre">=</span> <span class="pre">001*</span></code>, then <code class="docutils literal notranslate"><span class="pre">R1</span></code>, <code class="docutils literal notranslate"><span class="pre">R2</span></code>, <code class="docutils literal notranslate"><span class="pre">R3</span></code>, <code class="docutils literal notranslate"><span class="pre">R4</span></code>, <code class="docutils literal notranslate"><span class="pre">R5</span></code>, <code class="docutils literal notranslate"><span class="pre">R7</span></code> can all be possible matches. Therefore, we will need another trie at the end of this branch to filter the sources. In this example, we need to build 4 source tries and each of them will take a space in the memory.</p>
<p><img alt="" src="https://i.imgur.com/QQADoWP.png" /></p>
<p>We can find out that a source rule in this appoach can appear in multiple source tries. For example, <code class="docutils literal notranslate"><span class="pre">S7</span></code> appears in all the for tries and it causes duplications.</p>
<p>So the challenge for this approach is, when the network grows large enough, it can be impossible to fit the duplicated source in tries into the memory. This is called the <strong>memory explosion</strong> issue.</p>
</section>
<section id="packet-classification-fast-solution-2-backtracking">
<h3>(6) Packet Classification Fast Solution 2: Backtracking<a class="headerlink" href="#packet-classification-fast-solution-2-backtracking" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The opposite approach of set-pruning is backtracking. Suppose we have a packet with a destination <code class="docutils literal notranslate"><span class="pre">D</span></code> and a source <code class="docutils literal notranslate"><span class="pre">S</span></code>. Then,</p>
<ul class="simple">
<li><p>First, the algorithm goes through the destination trie and finds the longest prefix match. It then stores every ancestor prefix of <code class="docutils literal notranslate"><span class="pre">D</span></code> that points to a non-empty source tree.</p></li>
<li><p>Then it goes backup and search the source trie associated with every ancestor prefix of <code class="docutils literal notranslate"><span class="pre">D</span></code>.</p></li>
</ul>
<p>What we can find in this approach is that there will be no duplicated tries. We will have only one destination trie and one source trie.</p>
<p>However, the challenge of this approach is the lookup cost. Because a single source trie can be higher than multiple shallow source tries.</p>
</section>
<section id="packet-classification-fast-solution-3-grid-of-tries">
<h3>(7) Packet Classification Fast Solution 3: Grid of Tries<a class="headerlink" href="#packet-classification-fast-solution-3-grid-of-tries" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The grid of tries approach is a combination of those two approaches. Rather than tries, this approach has a data structure that looks more like a network.</p>
<p>As we have discussed, the problem of set-pruning trees is multiple sources appears in different tries. So the idea is to keep a single source trie for a single source, and we add edges that across the the source tries to target the match.</p>
<p>Here‚Äôs an example using the grid of tries approach.</p>
<p><img alt="" src="https://i.imgur.com/XRk1fvh.png" /></p>
</section>
</section>
<section id="packet-scheduling">
<h2>2. Packet Scheduling<a class="headerlink" href="#packet-scheduling" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="reasons-for-scheduling">
<h3>(1) Reasons for Scheduling<a class="headerlink" href="#reasons-for-scheduling" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>We are maintaining packet scheduling because of the following reasons,</p>
<ul class="simple">
<li><p>each crosspoint in the crossbar needs control (on/off)</p></li>
<li><p>maximize the number of input/output links pairs for parallel</p></li>
</ul>
</section>
<section id="scheduling-algorithm-1-take-a-ticket-algorithm">
<h3>(2) Scheduling Algorithm 1: Take a Ticket Algorithm<a class="headerlink" href="#scheduling-algorithm-1-take-a-ticket-algorithm" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Take a ticket algorithm is like a ‚Äúticket assign, done, reallocate‚Äù workflow and it has the following steps,</p>
<ul class="simple">
<li><p>When an input line wants to send a packet to the output line, it requests a <strong>ticket</strong></p></li>
<li><p>When the request reach the output line, it will process them in order and assign the ticket</p></li>
</ul>
<p>Let‚Äôs see an example. Suppose we have three input links <code class="docutils literal notranslate"><span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span></code>, and <code class="docutils literal notranslate"><span class="pre">C</span></code>, and we also have 4 output links <code class="docutils literal notranslate"><span class="pre">w</span></code>, <code class="docutils literal notranslate"><span class="pre">x</span></code>, <code class="docutils literal notranslate"><span class="pre">y</span></code>, <code class="docutils literal notranslate"><span class="pre">z</span></code>.</p>
<p>Then at a time, we have the following packets waiting to be sent,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">}</span>
<span class="n">B</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">}</span>
<span class="n">C</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">}</span>
</pre></div>
</div>
<p>First, each of them will request a ticket to <code class="docutils literal notranslate"><span class="pre">w</span></code> and suppose <code class="docutils literal notranslate"><span class="pre">w</span></code> will process in the order <code class="docutils literal notranslate"><span class="pre">A</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span></code>, and <code class="docutils literal notranslate"><span class="pre">C</span></code>.</p>
<p>So in round 1, there will be connections as follows,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">-&gt;</span> <span class="n">w</span>
</pre></div>
</div>
<p>In round 2, we have <code class="docutils literal notranslate"><span class="pre">A</span></code> send to <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code> send to <code class="docutils literal notranslate"><span class="pre">w</span></code> because <code class="docutils literal notranslate"><span class="pre">w</span></code> is no longer occupied by <code class="docutils literal notranslate"><span class="pre">A</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">}</span>
<span class="n">B</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">}</span>
<span class="n">C</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">}</span>

<span class="n">A</span> <span class="o">-&gt;</span> <span class="n">x</span>
<span class="n">B</span> <span class="o">-&gt;</span> <span class="n">w</span>
</pre></div>
</div>
<p>In round 3, we have the following status for input links and output links,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">A</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">y</span><span class="p">}</span>
<span class="n">B</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">}</span>
<span class="n">C</span> <span class="o">-&gt;</span> <span class="p">{</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">}</span>

<span class="n">A</span> <span class="o">-&gt;</span> <span class="n">y</span>
<span class="n">B</span> <span class="o">-&gt;</span> <span class="n">x</span>
<span class="n">c</span> <span class="o">-&gt;</span> <span class="n">w</span>
</pre></div>
</div>
</section>
<section id="problem-of-take-a-ticket-head-of-line-hol-blocking">
<h3>(3) Problem of Take a Ticket: Head of Line (HOL) Blocking<a class="headerlink" href="#problem-of-take-a-ticket-head-of-line-hol-blocking" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>From the discussion above, we can find out when <code class="docutils literal notranslate"><span class="pre">A</span></code> sends its packet to <code class="docutils literal notranslate"><span class="pre">w</span></code>, the entire queue for <code class="docutils literal notranslate"><span class="pre">B</span></code> and <code class="docutils literal notranslate"><span class="pre">C</span></code> are waiting. We refer to this problem as <strong>head-of-line (HOL)</strong> blocking.</p>
<p>So head-of-the-line (HOL) blocking is a queued packet in an input queue must wait for transfer through the <strong>fabric</strong> (even though its output port is free) because it is blocked by another packet at the head of the line.</p>
</section>
<section id="hol-avoidance-solution-1-faster-fabric">
<h3>(4) HOL Avoidance Solution 1: Faster Fabric<a class="headerlink" href="#hol-avoidance-solution-1-faster-fabric" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Because HOL is caused by the occupied fabric, then a simple idea to deal with it is to make the fabric much faster than the input links.</p>
<p>In order to avoid any of the blocks in the input queue, in the worst case we need to have the fabric <code class="docutils literal notranslate"><span class="pre">N</span></code> times faster than the input links, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of the inputs.</p>
<p>A practical implementation of this approach is called the <strong>Knockout scheme</strong>. This means to split packets into fixed sized chunks called <strong>cells</strong>. If the average splits for a packet is <code class="docutils literal notranslate"><span class="pre">K</span></code>, then we are able to slower the input queue by <code class="docutils literal notranslate"><span class="pre">K</span></code> times so the fabric is <code class="docutils literal notranslate"><span class="pre">K</span></code> times faster than the input queue. This technique was used in Asynchronous Transfer Mode (ATM) networks once and now it‚Äôs replaced by some other technologies like Ethernet.</p>
<p>In practice, the expected splits <code class="docutils literal notranslate"><span class="pre">K</span></code> is usually smaller than <code class="docutils literal notranslate"><span class="pre">N</span></code>, so we have to accommodate some scenarios,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">K</span> <span class="pre">=</span> <span class="pre">N</span></code>: No packet queue caused by fabric</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">K</span> <span class="pre">&lt;</span> <span class="pre">N</span></code>: There‚Äôs a queue caused by fabric. The ATM network uses a switch called concentrator that connects multiple low-speed networks (input links) to a single <code class="docutils literal notranslate"><span class="pre">K</span></code> times faster high-speed links (fabric). Because <code class="docutils literal notranslate"><span class="pre">K</span> <span class="pre">&lt;</span> <span class="pre">N</span></code>, there will still be a queue in the fabric and in this case, the switch randomly picks one out of <code class="docutils literal notranslate"><span class="pre">N</span></code> outputs for connection. We use multiple 2-by-2 concentrators.</p></li>
</ul>
<p>As we used multiple 2-by-2 concentrators above, the network structure will be like a binary tree with each node in the tree represents a switch or concentrator that can be used to aggregate traffic from multiple inputs and forward it to a single output. In fact, this approach is complex to implement.</p>
</section>
<section id="hol-avoidance-solution-2-parallel-iterative-matching">
<h3>(5) HOL Avoidance Solution 2: Parallel Iterative Matching<a class="headerlink" href="#hol-avoidance-solution-2-parallel-iterative-matching" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Another idea to avoid blockings on the fabric is to do out-of-order packet forwarding on the input links. Although we still maintain the packet queues on the input link, we send more ticket requests to the output of some future packets.</p>
<p>In this case, even the head is blocked in the input queue, we can still go ahead for forwarding some later packets if we are able to establish a connection.</p>
<p>Because this approach avoides the HOL issue, it‚Äôs clearly more efficient than the take a ticket approach.</p>
</section>
<section id="scheduling-algorithm-2-fifo-with-tail-drop">
<h3>(6) Scheduling Algorithm 2: FIFO with Tail Drop<a class="headerlink" href="#scheduling-algorithm-2-fifo-with-tail-drop" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>After talking about take a ticket approach, let‚Äôs look into some other simple scheduling algorithm used when new packets come to a router.</p>
<p>Suppose we have some new packets coming in through the input links, then the simplest approach to maintain a packet queue at a input link is by maintaining an <strong>FIFO queue</strong> for packets.</p>
<p>When this queue is full, packets will be dropped from the tail of the queue (where new packets come in). This method to avoid buffer overflow is called <strong>tail-drop</strong> and it results in fast scheduling decisions. But it can also cause potential loss in important data packets.</p>
</section>
<section id="quality-of-service-qos">
<h3>(7) Quality of Service (QoS)<a class="headerlink" href="#quality-of-service-qos" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>In the real world, it‚Äôs very important to provide the quality of service (QoS) for a computer network. The QoS refers to a set of mechanisms for the following functions,</p>
<ul class="simple">
<li><p>Prioritize certain types of network traffic over others: times-sensitive services like real-time chatting and video stream</p></li>
<li><p>Implement traffic shaping</p></li>
<li><p>Implement packet classification</p></li>
<li><p>Implement queue management</p></li>
<li><p>Implement fair bandwidth allocation</p></li>
</ul>
<p>QoS is used to guarantees to a <strong>flow of packets</strong>, which refers to a stream of packets that travels the same route from source to destination. A flow of packets should also require the same level of service at each intermediate router and gateway. In addition, flows must be identifiable using fields in the packet headers.</p>
<p>In order to provide QoS, FIFO with tail drop is clearly not enough. Therefore, we will talk about some more complex scheduling algorithms in the next section.</p>
</section>
<section id="reasons-for-complex-scheduling-algorithms">
<h3>(8) Reasons for Complex Scheduling Algorithms<a class="headerlink" href="#reasons-for-complex-scheduling-algorithms" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Here are more reasons to use complex scheduling algorithms,</p>
<ul class="simple">
<li><p>router support for congestion</p></li>
<li><p>fair sharing of links among competing flows</p></li>
<li><p>providing QoS garantees to flows</p></li>
</ul>
</section>
<section id="fifo-with-tail-drop-vs-round-robin">
<h3>(9) FIFO with Tail Drop vs Round Robin<a class="headerlink" href="#fifo-with-tail-drop-vs-round-robin" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>One problem of FIFO with tail drop is that it will result in some packets being dropped randomly. If a source sends many packets to router when its input buffer is full, it will lead to the fairness issue.</p>
<p>So solve this problem, we can easily think about the round-robin approach which takes packets from each flow in a cyclic oder. Each flow is given a certain amount of time to transmit before the next one comes in.</p>
<p>However, the flow with small packet sizes will result in getting served more frequently. To avoid this, researchers came up with bit-by-bit round robin.</p>
</section>
<section id="complex-scheduling-algorithm-1-1-bit-by-bit-round-robin">
<h3>(9) Complex Scheduling Algorithm 1-1: Bit-by-bit Round Robin<a class="headerlink" href="#complex-scheduling-algorithm-1-1-bit-by-bit-round-robin" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Bit-by-bit round robin is a imaginary system which doesn‚Äôt actually exist in the real world. It is a simple idea for dealing with the fairness issue of round robin. The idea is to take 1 bit from each active flow in a round robin manner so it ensures fairness in bandwith allocation.</p>
<p>We can not implement it because we can not split packets to bits. Although it‚Äôs not a real-world implementation, we can still do some calculations to check its performance.</p>
<p>Let‚Äôs suppose the following conditions,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">R(t)</span></code>: current round number at time <code class="docutils literal notranslate"><span class="pre">t</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Œº</span></code>: a router can send <code class="docutils literal notranslate"><span class="pre">Œº</span></code> bits per time unit</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">N</span></code>: number of active flows</p></li>
</ul>
<p>So the rate of increase of <code class="docutils literal notranslate"><span class="pre">R</span></code> is,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rate</span> <span class="o">=</span> <span class="n">dR</span> <span class="o">/</span> <span class="n">dt</span> <span class="o">=</span> <span class="n">Œº</span> <span class="o">/</span> <span class="n">N</span>
</pre></div>
</div>
<p>Suppose we have a packet of size <code class="docutils literal notranslate"><span class="pre">p</span></code> bits to transmit, then the time it takes should be,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">time</span> <span class="o">=</span> <span class="n">size</span> <span class="o">/</span> <span class="n">rate</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">N</span> <span class="o">/</span> <span class="n">Œº</span>
</pre></div>
</div>
<p>We can find out that this result is not depend on the number of the backlogged queues.</p>
<p>Also suppose this packet is the i-th packet in the flow <code class="docutils literal notranslate"><span class="pre">Œ±</span></code>.</p>
<ul class="simple">
<li><p>If this packet reach an empty input queue, then it reaches the head of queue at the current round <code class="docutils literal notranslate"><span class="pre">R(t)</span></code></p></li>
<li><p>If not, then it needs to wait for the <code class="docutils literal notranslate"><span class="pre">i</span> <span class="pre">-</span> <span class="pre">1</span></code> packets at the front to finish. We denote the round number as <code class="docutils literal notranslate"><span class="pre">F(i-1)</span></code></p></li>
</ul>
<p>So the round number at which the packet reaches the head is given by,</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">S</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">=</span> <span class="nb">max</span><span class="p">{</span><span class="n">R</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">F</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)}</span>
</pre></div>
</div>
<p>The round number at which a packet finishes, which depends only on the size of the packet, is given by</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">F</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">S</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">p</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">p(i-1)</span></code> means the size of the (i-1)-th packet in flow <code class="docutils literal notranslate"><span class="pre">Œ±</span></code>.</p>
<p>With the two equations above, we can calculate the finish round of every packet in a queue. We will use the finish round values in the next section.</p>
</section>
<section id="complex-scheduling-algorithm-1-2-packet-level-fair-queuing">
<h3>(10) Complex Scheduling Algorithm 1-2: Packet-level Fair Queuing<a class="headerlink" href="#complex-scheduling-algorithm-1-2-packet-level-fair-queuing" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>This packet-level fair strategy emulates the bit-by-bit fair queueing by sending the packet which has the smallest finishing round number.</p>
<p>It will calculate the finish round values for each packet in different flows and choose to schedule the one with the smallest finish round value.</p>
<p>Although this method provides fairness, it also introduces new complexities. We will need to keep track of the finishing time at which the head packet of each queue would depart and choose the earliest one. This requires a priority queue implementation, which has time complexity which is logarithmic in the number of flows.</p>
<p>Additionally, if a new queue becomes active, all timestamps may have to change ‚Äì which is an operation with time complexity linear in the number of flows. Thus, the time complexity of this method makes it hard to implement at gigabit speeds.</p>
<p>Therefore, although the bit-by-bit round robin gave us bandwidth and delay guarantees, the time complexity was too high.</p>
</section>
<section id="complex-scheduling-algorithm-2-deficit-round-robin-drr">
<h3>(11) Complex Scheduling Algorithm 2: Deficit Round Robin (DRR)<a class="headerlink" href="#complex-scheduling-algorithm-2-deficit-round-robin-drr" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Let‚Äôs see an idea that makes everything easier. It‚Äôs called deficit round robin. The idea is to control of size rather than the time (compared with round robin) and allocate a fixed quantum size for each flow in each round instead of doing 1 bits (compared with bit-by-bit round robin).</p>
<p>Here are the terms we use in this case,</p>
<ul class="simple">
<li><p>Quantim size: a single, fixed value represents the number of bits we are able to accumulate for each flow at a round.</p></li>
<li><p>Deficit counters: we have one deficit counter assigned to one flow and the value of it represents how many bits we can send in this round. At the beginning of each round, it will use its remaining value to add the quantim size. Initially, all the counters will be set to 0s.</p></li>
</ul>
<p>In one round, the packet sending process will stop in the following cases,</p>
<ul class="simple">
<li><p>the non-sent packet queue in the flow is empty</p></li>
<li><p>the specific deficit counter shows a value that is not enough to send the next packet in the flow</p></li>
</ul>
</section>
</section>
<section id="traffic-scheduling">
<h2>3. Traffic Scheduling<a class="headerlink" href="#traffic-scheduling" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="reasons-for-traffic-scheduling">
<h3>(1) Reasons for Traffic Scheduling<a class="headerlink" href="#reasons-for-traffic-scheduling" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>There are scenarios where we want to set bandwidth guarantees for flows in the same queue without separating them.</p>
<p>For example, we can have a scenario where we want to limit a specific type of traffic (eg news traffic or email traffic) in the network to no more than X Mbps, without putting this traffic into a separate queue.</p>
</section>
<section id="traffic-policing">
<h3>(2) Traffic Policing<a class="headerlink" href="#traffic-policing" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Traffic policing and traffic shaping are two related but distinct mechanisms used in computer networks to control the flow of data traffic. Let‚Äôs first discuss traffic policing.</p>
<p>Traffic policing involves monitoring the rate of incoming network traffic and <strong>enforcing a maximum</strong> rate or bandwidth limit. If the incoming traffic exceeds the limit, packets may be dropped or marked as non-conforming.</p>
<p>When traffic rate reaches the maximum configured rate, excess traffic is either dropped, or the setting or ‚Äúmarking‚Äù of a packet is changed. The output rate appears as a <strong>saw-toothed wave</strong>.</p>
<p><img alt="" src="https://i.imgur.com/Aw0A2yn.png" /></p>
</section>
<section id="traffic-shaping">
<h3>(3) Traffic Shaping<a class="headerlink" href="#traffic-shaping" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Traffic shaping, on the other hand, involves delaying or buffering packets to ensure that they are transmitted at a <strong>steady rate</strong>, even if the actual rate of incoming traffic fluctuates.</p>
<p>A <strong>shaper</strong> typically retains excess packets in a queue or a buffer and this excess is scheduled for later transmission. The result is that excess traffic is delayed instead of dropped. Thus, when the data rate is higher than the configured rate, the flow is shaped or smoothed.</p>
<p><img alt="" src="https://i.imgur.com/sNn0iey.png" /></p>
<p>Traffic shaping and policing can work together.</p>
</section>
<section id="traffic-scheduling-approach-1-token-bucket-shaping">
<h3>(4) Traffic Scheduling Approach 1: Token Bucket Shaping<a class="headerlink" href="#traffic-scheduling-approach-1-token-bucket-shaping" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The idea of this approach is to maintain an extra token bucket with tokens generated by a fixed rate. The token bucket and the data buffer are suppose to have the same length. Each incoming packet must take a token from the bucket in order to be transmitted.</p>
<p>When the token bucket is full with tokens, then additional tokens are dropped. When a packet arrives, it can go through if there are enough tokens. If not, the packet needs to wait until enough tokens are in the bucket.</p>
<p>Suppose the token bucket has a size of <code class="docutils literal notranslate"><span class="pre">B</span></code>, then burst is limited to <code class="docutils literal notranslate"><span class="pre">B</span></code> bits per second.</p>
<p>In pactice, the token bucket is implemented through a timer and a counter.</p>
</section>
<section id="traffic-scheduling-approach-1-token-bucket-policing">
<h3>(5) Traffic Scheduling Approach 1: Token Bucket Policing<a class="headerlink" href="#traffic-scheduling-approach-1-token-bucket-policing" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The problem of token bucket shaping is that we have one queue per flow so even when some other flows have empty bucket, we are blocked and we can not use them.</p>
<p>To fully use all the queues, we can combine multiple queues to a single long queue. However, in this case, the token bucket shaping will be modified to token bucket policing.</p>
<p>So when a packet arrives will need to have tokens at the bucket or if the token bucket is empty, the packet is dropped.</p>
</section>
<section id="traffic-scheduling-approach-2-leaky-bucket">
<h3>(6) Traffic Scheduling Approach 2: Leaky Bucket<a class="headerlink" href="#traffic-scheduling-approach-2-leaky-bucket" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Leaky Bucket is an algorithm which can be used in both traffic policing and traffic shaping.</p>
<p>To learn about leaky bucket, we have to know the following terms,</p>
<ul class="simple">
<li><p>bucket capacity <code class="docutils literal notranslate"><span class="pre">b</span></code>: epresents a buffer that holds packets</p></li>
<li><p>leak rate <code class="docutils literal notranslate"><span class="pre">r</span></code>: constant rate at which the packets are allowed to enter the network</p></li>
</ul>
<p>If an arriving packet does not cause an overflow when added to the bucket, it is said to be <strong>conforming</strong>. Otherwise, if the incoming traffic rate exceeds the leak rate, the bucket will overflow, and the excess traffic will be dropped or marked as <strong>non-conforming</strong>.</p>
<p>Irrespective of the input rate of packets, the output rate is constant which leads to uniform distribution of packets send to the network. This algorithm can be implemented as a single server queue.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="note8.html" class="btn btn-neutral float-left" title="Computer Network 8 | Introduction to Routers and Prefix Match" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../HPC/note1.html" class="btn btn-neutral float-right" title="High Performance Computing 1 | Memory Locality Theory" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Yufeng Xing.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>